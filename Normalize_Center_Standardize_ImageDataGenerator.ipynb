{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Normalize_Center_Standardize_ImageDataGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCBmGkcS3vf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "8f338f13-849a-439f-bb47-34cfe4640123"
      },
      "source": [
        "# Importing the libraries\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# load dataset\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "# one hot encode target values\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)\n",
        "# confirm scale of pixels\n",
        "print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))\n",
        "print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "Train min=0.000, max=255.000\n",
            "Test min=0.000, max=255.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ttXAkRD4dv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "caa15224-8dc7-4d1c-e44d-cd0ec876c4cc"
      },
      "source": [
        "# Create generator (1.0/255.0 = 0.003921568627451)\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "# prepare an iterators to scale images\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches train=938, test=157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6n3x3cj4r4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "146ca6e8-4846-47ad-91cf-0b778bafd200"
      },
      "source": [
        "# confirm the scaling works\n",
        "batchX, batchy = train_iterator.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch shape=(64, 28, 28, 1), min=0.000, max=1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wNAhirR44ob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "d40fcb2c-ac05-4119-a9e2-6b0fae859fcf"
      },
      "source": [
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit model with generator\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n",
        "# evaluate model\n",
        "_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.1715 - acc: 0.9479\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.0524 - acc: 0.9837\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.0391 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.0301 - acc: 0.9904\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.0228 - acc: 0.9926\n",
            "Test Accuracy: 99.020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YvJFvH74yGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Centering the Image\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzvJa9_I59o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(samplewise_center=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZNIKASM5_KZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "31a41abc-af69-40dd-e8eb-8fa596b64f89"
      },
      "source": [
        "# report per-image mean\n",
        "print('Means train=%.3f, test=%.3f' % (trainX.mean(), testX.mean()))\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)\n",
        "print('Data Generator Mean: %.3f' % datagen.mean)\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=len(trainX), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Means train=33.318, test=33.791\n",
            "Data Generator Mean: 33.318\n",
            "(64, 28, 28, 1) 0.05938172\n",
            "(60000, 28, 28, 1) -1.9512918e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14eIlHWM69I-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f408a1bd-ea9a-45c2-cfda-e9d0dddabda5"
      },
      "source": [
        "# prepare an iterators to scale images\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit model with generator\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n",
        "# evaluate model\n",
        "_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches train=938, test=157\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 1.0930 - acc: 0.9014\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0604 - acc: 0.9819\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0477 - acc: 0.9854\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0389 - acc: 0.9888\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0346 - acc: 0.9894\n",
            "Test Accuracy: 98.650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzRh0Q4Z7zKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "95473d9b-8d50-43aa-9a27-1e43965b886c"
      },
      "source": [
        "# report pixel means and standard deviations\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=len(trainX), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=33.318 (78.567), test=33.791 (79.172)\n",
            "Data Generator mean=33.318, std=78.567\n",
            "(64, 28, 28, 1) 0.014971721 1.0204856\n",
            "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fye8M6-B8Bo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "366bf845-928d-4f31-c3c4-505eb7a5ad4e"
      },
      "source": [
        "# create generator to standardize images\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate mean on training dataset\n",
        "datagen.fit(trainX)\n",
        "# prepare an iterators to scale images\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit model with generator\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n",
        "# evaluate model\n",
        "_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches train=938, test=157\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.1429 - acc: 0.9562\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0454 - acc: 0.9860\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0322 - acc: 0.9900\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0234 - acc: 0.9927\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0180 - acc: 0.9942\n",
            "Test Accuracy: 99.060\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}